{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTMExample.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOSrKQ1IbMoLGjN+mePsMkt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cmcvista/MLHelloWorld/blob/main/LSTMExample.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5UVpxVppA7XE"
      },
      "source": [
        "# LSTM Stock Price Prediction Example\n",
        "\n",
        "Assuming the stock price should be dependent to history records, this example uses Long-Short-Term-Memory Neural Network to find the pattern in stock price, and then make some sensible predictions.\n",
        "\n",
        "*Reference:*\n",
        "- https://www.datacamp.com/community/tutorials/lstm-python-stock-market\n",
        "- https://github.com/thushv89/datacamp_tutorials/blob/master/Reviewed/lstm_stock_market_prediction.ipynb\n",
        "- https://www.tensorflow.org/guide/keras/rnn\n",
        "- https://www.analyticsvidhya.com/blog/2017/12/fundamentals-of-deep-learning-introduction-to-lstm/\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYwa88n8Bwh0"
      },
      "source": [
        "# Load Data\n",
        "import pandas as pd\n",
        "df = pd.read_csv(\"KO.csv\")\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0cbYwspCpD4",
        "outputId": "044d6991-9c51-4970-8b0c-357142634cd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "# Display the CSV content\n",
        "df.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2019-11-08</td>\n",
              "      <td>52.459999</td>\n",
              "      <td>52.599998</td>\n",
              "      <td>52.090000</td>\n",
              "      <td>52.209999</td>\n",
              "      <td>50.501057</td>\n",
              "      <td>7141800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2019-11-11</td>\n",
              "      <td>52.330002</td>\n",
              "      <td>52.369999</td>\n",
              "      <td>51.779999</td>\n",
              "      <td>51.840000</td>\n",
              "      <td>50.143169</td>\n",
              "      <td>8198300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2019-11-12</td>\n",
              "      <td>51.910000</td>\n",
              "      <td>51.910000</td>\n",
              "      <td>51.580002</td>\n",
              "      <td>51.709999</td>\n",
              "      <td>50.017422</td>\n",
              "      <td>12656900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2019-11-13</td>\n",
              "      <td>52.180000</td>\n",
              "      <td>52.450001</td>\n",
              "      <td>51.959999</td>\n",
              "      <td>52.410000</td>\n",
              "      <td>50.694511</td>\n",
              "      <td>12257900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2019-11-14</td>\n",
              "      <td>52.529999</td>\n",
              "      <td>52.669998</td>\n",
              "      <td>52.349998</td>\n",
              "      <td>52.630001</td>\n",
              "      <td>50.907310</td>\n",
              "      <td>8660300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Date       Open       High        Low      Close  Adj Close    Volume\n",
              "0  2019-11-08  52.459999  52.599998  52.090000  52.209999  50.501057   7141800\n",
              "1  2019-11-11  52.330002  52.369999  51.779999  51.840000  50.143169   8198300\n",
              "2  2019-11-12  51.910000  51.910000  51.580002  51.709999  50.017422  12656900\n",
              "3  2019-11-13  52.180000  52.450001  51.959999  52.410000  50.694511  12257900\n",
              "4  2019-11-14  52.529999  52.669998  52.349998  52.630001  50.907310   8660300"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5s7gHqEC1Hd",
        "outputId": "e5151d84-02f9-44b7-abbd-80897f7bde6a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# For simplicity, we only want Open price\n",
        "open_prices = df.loc[:,'Open'].array\n",
        "print(\"Size: \", open_prices.size)\n",
        "\n",
        "# Set training and testing dataset size\n",
        "train_data_len = open_prices.size*7//10   # 80%\n",
        "\n",
        "# Separate training and testing dataset\n",
        "train_data = open_prices[:train_data_len]\n",
        "test_data = open_prices[train_data_len:]\n",
        "print(train_data.size)\n",
        "print(test_data.size)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size:  252\n",
            "176\n",
            "76\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqrfeiZe6h73",
        "outputId": "96c580b0-48fe-4982-912b-17861735c5e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Generate one batch sized with \"batch_size\" from a \"data\"\n",
        "# For example\n",
        "# input_dataset: x0, x1 ... x100,\n",
        "# data: x0, x10, x20 ... x90\n",
        "# label: x1, x11, x21 ... x91\n",
        "def gen_one_batch(input_dataset, batch_size):\n",
        "  batch_data = np.zeros(batch_size, dtype=np.float32)\n",
        "  batch_labels = np.zeros(batch_size, dtype=np.float32)\n",
        "  for i in range(batch_size):\n",
        "    batch_data[i] = input_dataset[batch_size*i]\n",
        "    batch_labels[i]= input_dataset[batch_size*i+1]\n",
        "  return batch_data, batch_labels\n",
        "\n",
        "# Generate many batches sized \"batch_size\"\n",
        "# For example\n",
        "# no_of_batches = 3, batch_size = 10\n",
        "# input_dataset: x0, x1 ... x100,\n",
        "# data: [x0, x10, x20 ... x90], [x1, x11, x21 ... x91], [x2, x12, x22 ... x92]\n",
        "# labels: [x1, x11, x21 ... x91], [x2, x12, x22 ... x92], [x3, x13, x23 ... x93]\n",
        "def gen_batches(input_dataset, no_of_batches, batch_size):\n",
        "  data_batches, labels_batches = [], []\n",
        "  for i in range(no_of_batches):\n",
        "    data, labels = gen_one_batch(input_dataset[i:], batch_size)\n",
        "    data_batches.append(data)\n",
        "    labels_batches.append(labels)\n",
        "  return data_batches, labels_batches\n",
        "\n",
        "# One batch contains 6 days data\n",
        "batch_size = 6\n",
        "train_X, train_Y = gen_batches(train_data, train_data.size//batch_size, batch_size)\n",
        "test_X, test_Y = gen_batches(test_data, test_data.size//batch_size, batch_size)\n",
        "\n",
        "print(\"Training Set: \", len(train_X))\n",
        "print(\"Testing Set: \", len(test_X))\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Set:  29\n",
            "Testing Set:  12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlpuYIYfFa32"
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "input_dim = batch_size\n",
        "units = 20\n",
        "output_size = batch_size\n",
        "\n",
        "# Build the RNN model\n",
        "def build_model(allow_cudnn_kernel=True):\n",
        "    # CuDNN is only available at the layer level, and not at the cell level.\n",
        "    # This means `LSTM(units)` will use the CuDNN kernel,\n",
        "    # while RNN(LSTMCell(units)) will run on non-CuDNN kernel.\n",
        "    if allow_cudnn_kernel:\n",
        "        # The LSTM layer with default options uses CuDNN.\n",
        "        lstm_layer = keras.layers.LSTM(units, input_shape=(None, input_dim))\n",
        "    else:\n",
        "        # Wrapping a LSTMCell in a RNN layer will not use CuDNN.\n",
        "        lstm_layer = keras.layers.RNN(\n",
        "            keras.layers.LSTMCell(units), input_shape=(None, input_dim)\n",
        "        )\n",
        "    model = keras.models.Sequential(\n",
        "        [\n",
        "            lstm_layer,\n",
        "            #keras.layers.BatchNormalization(),\n",
        "            keras.layers.Dense(output_size),\n",
        "        ]\n",
        "    )\n",
        "    return model"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRe-OegONNVv",
        "outputId": "f16ad117-0af6-493d-ed83-0f59175c4088",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = build_model(allow_cudnn_kernel=False)\n",
        "\n",
        "model.compile(\n",
        "    loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "    optimizer=\"sgd\",\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "rnn (RNN)                    (None, 20)                2160      \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 6)                 126       \n",
            "=================================================================\n",
            "Total params: 2,286\n",
            "Trainable params: 2,286\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apntSAqaPQ-Z",
        "outputId": "d4fa8e31-a39e-4c60-9e0e-5ec87f6b1c13",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_X_reshaped = np.reshape(train_X, (len(train_X), 1, len(train_X[0])))\n",
        "train_Y_reshaped = np.reshape(train_Y, (len(train_Y), len(train_Y[0])))\n",
        "\n",
        "test_X_reshaped = np.reshape(test_X, (len(test_X), 1, len(test_X[0])))\n",
        "test_Y_reshaped = np.reshape(test_Y, (len(test_Y), len(test_Y[0])))\n",
        "\n",
        "model.fit(train_X_reshaped, train_Y_reshaped, batch_size=batch_size, epochs=5)\n",
        "predictions = model(test_X_reshaped)\n",
        "print(predictions)\n",
        "print(test_Y_reshaped)\n",
        "\n",
        "results = model.evaluate(test_X_reshaped, test_Y_reshaped, batch_size=batch_size)\n",
        "print(\"test loss, test acc:\", results)\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 637.0010 - accuracy: 0.1379\n",
            "Epoch 2/5\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 645.7293 - accuracy: 0.8276\n",
            "Epoch 3/5\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 672.9412 - accuracy: 0.8276\n",
            "Epoch 4/5\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 722.1750 - accuracy: 0.8276\n",
            "Epoch 5/5\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 776.4376 - accuracy: 0.8276\n",
            "tf.Tensor(\n",
            "[[74.67931  76.10727  76.3457   75.96924  76.654724 78.49681 ]\n",
            " [74.67931  76.107254 76.34567  75.9693   76.65476  78.49681 ]\n",
            " [74.679306 76.10724  76.34564  75.969345 76.65479  78.496796]\n",
            " [74.6793   76.107216 76.34558  75.96947  76.65486  78.49679 ]\n",
            " [74.679306 76.10723  76.34561  75.969406 76.65483  78.496796]\n",
            " [74.679306 76.10724  76.34563  75.969406 76.65482  78.4968  ]\n",
            " [74.67931  76.10722  76.34558  75.9695   76.654884 78.496796]\n",
            " [74.67931  76.10723  76.34561  75.96945  76.65486  78.4968  ]\n",
            " [74.67931  76.10723  76.34561  75.96947  76.65486  78.4968  ]\n",
            " [74.67931  76.10725  76.34564  75.96939  76.65481  78.49681 ]\n",
            " [74.67931  76.10725  76.34563  75.96942  76.65483  78.49681 ]\n",
            " [74.679306 76.10722  76.3456   75.96948  76.65487  78.4968  ]], shape=(12, 6), dtype=float32)\n",
            "[[48.4  47.14 48.46 48.12 48.25 50.94]\n",
            " [48.18 46.29 48.3  47.27 48.75 50.93]\n",
            " [48.34 46.9  48.26 47.34 49.8  49.6 ]\n",
            " [48.14 46.66 48.34 47.43 49.31 50.35]\n",
            " [47.67 47.47 48.32 48.   49.36 50.4 ]\n",
            " [47.44 48.06 48.2  47.76 51.4  50.97]\n",
            " [47.14 48.46 48.12 48.25 50.94 51.  ]\n",
            " [46.29 48.3  47.27 48.75 50.93 50.95]\n",
            " [46.9  48.26 47.34 49.8  49.6  50.22]\n",
            " [46.66 48.34 47.43 49.31 50.35 50.75]\n",
            " [47.47 48.32 48.   49.36 50.4  49.75]\n",
            " [48.06 48.2  47.76 51.4  50.97 49.11]]\n",
            "2/2 [==============================] - 0s 1ms/step - loss: 725.8658 - accuracy: 0.6667\n",
            "test loss, test acc: [725.8657836914062, 0.6666666865348816]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}